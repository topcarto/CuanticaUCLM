Este documento intentará explicar el contenido del artículo "Ising formulations of many NP problems by Andrew Lucas" de Frontiersin.
Enlace: https://www.frontiersin.org/articles/10.3389/fphy.2014.00005/full

1. INTRODUCCIÓN

1.1. Quantum Adiabatic Optimization
En la primera parte del artículo, habla de usar Adiabatic Quantum Optimization (AQO) para resolver problemas de optimización cuántica. Para ello, se habla de usar dos
Hamiltonianos cuánticos; uno cuyo estado base tenga encriptada la solución al problema llamado Hp, y otro cuyo estado base sea "fácil" de encontrar y de preparar
llamado Ho. Con estos hamiltonianos, si preparamos un sistema cuántico que esté en el estado base de Ho, y se cambia adiabáticamente hasta llegar a Hp con la fórmula:

![AQO]
(https://raw.githubusercontent.com/topcarto/CuanticaUCLM/Knapsack/AQO.PNG)

Siendo T la cantidad de tiempo adecuada para que el AQO funcione, cuando t sea igual a T, obtendremos una de las posibles soluciones al problema. Vamos a explicar esto
más detalladamente.

El AQO se basa en el teorema adiabático. Este teorema cuántico dice que un sistema físico permanece en su eigenstate si una perturbación lo cambia lo suficientemente
lento y hay diferencia entre su eigenstate y el resto del espectro hamiltoniano. O en otras palabras, si un sistema cambia demasiado rápido no tiene tiempo suficiente
para adaptarse y cambiar de forma, por lo que se queda en su estado base. Este "tiempo" que necesitamos para que se de ese cambio es el mismo que aparece en la fórmula
de Andrew. Debe ser lo suficientemente grande como para que el sistema pueda pasar desde Ho hasta Hp.

El documento después habla que debido a este tiempo que tenemos que darle al sistema para adaptarse, hay gente que piensa que usar AQO para resolver problemas 
NP-completos es menos eficiente que los algoritmos clásicos, ya que normalmente uno se encuentra que la complejidad de un problema sea:

T= O[exp (α * N^β)]

Sin embargo, aún cabe la posibilidad de que los coeficientes α y β sean más pequeños que en los algoritmos clásicos. La teoría dice que esto puede ser posible expresando
Hp como un Ising Sping glass, con la fórmula:

H (s1,…,sN)= −∑(i<j) Jij * si * sj − ∑(i=1, N) hi * si

O más simplemente:

Hp = H(σz1,…,σzN)

Donde σzi es una matriz de Pauli 2x2, Jij y hi son números reales correspondientes a la energía que tiene la relación entre sus índices (siendo los índices de hi i-i), y
si el valor de ese qubit en un determinado escenario. Cabe destacar que puede que esta clase de Hamiltonianos no sean suficientes para esta metodología, por lo que puede
que se necesite usar unos hamiltonianos especiales llamados Hamiltonianos "stoquastic"; pero por ahora vamos a concentrarnos en los Hamiltonianos básicos.

1.2. Ising Spin glasses

Los Ising Spin glasses han sido siempre problemas NP-hard, por lo que tiene sentido que guarden relación con otros problemas NP. El papel habla que para más simplicidad,
a partir de ahora consideraremos que los problemas NP-hard son de optimización. Los problemas NP-complete han atraído la atención de muchas personas, por lo que es
normal que estos problemas estén más investigados y explicados que los NP-hard.

Analogías entre la física estadística de los problemas NP y los Ising Spin glasses han sido estudiadas frecuentemente en el pasado, y han sido usadas para construir
algortimos aproximados para problemas en computadores clásicos.

1.3. The Goal of This Paper

Matemáticamente, el hecho de que un problema sea NP-complete significa que puede ser reinterpretado como un problema de optimización pseudo-booleano. Como estos
problemas a menudo nos llevan a interacciones de 3 o más cuerpos en H (s1s2s3), podemos reducir el problema para que sea un problema de Ising Spin glass introduciendo
un número polinómico de spins auxiliares con múltiples interacciones entre dos cuerpos. Artilugios clásicos son bastante útiles para muchos problemas en física ya que
la energía de los Hamiltonianos contienen interacciones de 3 cuerpos. Sin embargo, en los problemas genéricos, esto es un procedimiento poco eficiente, ya que la
complejidad del polinomio puede aumentar drásticamente.


4. Covering and Packaging Problems

Los problemas de "Covering and Packaging" se pueden resumir con la pregunta: ¿Cómo puedo coger elementos de un grafo de forma que se quede "cubierto" de una forma
simple? En estos problemas hay restricciones que deben ser cumplidas obligatoriamente. Estos problemas son de los más famosos ya que son el único tipo de problemas
que se puede hacer con un simple grafo aunque ni siquiera esté completo.

4.1. Exact Cover

En este problema, considera un dominio U con un conjunto de subdominios Vi ⊆ U, tal que el conjunto de los subdominios sea U. La pregunta es, ¿hay un subdominio,
llamado R, tal que sus elementos seas conjuntos desunidos y que la unión de sus elementos sea U? O en otras palabras, formar subconjuntos de forma que todos los 
elementos de U estén contenidos en ellos. El hamiltoniano que se propone es:

HA = A * ∑(α=1)(n)(1 − ∑(i:α ∈ Vi) * xi) ^ 2.

Siendo α los elementos de U, y siendo i el indice de los subconjuntos Vi. Cuando todos los elementos han sido incluidos exactamente una vez, HA = 0, lo que
significaría que los elementos también están desunidos. Si existe un estado en el que HA = 0, ese estado correspondería con la solución al problema. Si ese estado es
degenerativo (que hay varios estados base), entonces habría múltiples soluciones a este problema. Se necesitan N spins.

Este problema se puede complicar más para encontrar el R más pequeño, haciendo que este problema sea NP-Hard. Esto se consigue añadiendo un segundo hamiltoniano, HB
que es:

HB = B * ∑(i)(xi)

El estado base de este modelo será mB, siendo m el mínimo número de subconjuntos necesarios. Para conseguir el ratio adecuado de A/B, queremos codificar estas
constantes poniéndonos en el peor escenario posible que sería un número muy pequeño de subconjuntos con un solo elemento en común, cuya unión es U. Para que esto no
pase, podemos configurarlo para que sea: A > n * B; siendo n el número de elementos de U. Con este segundo hamiltoniano, se hace que la fórmula H = HA + HB se 
minimice todo lo posible.

4.2. Set Packing

Considerando la misma situación que antes, pero con una pregunta diferente: ¿Cuál es el mayor número de subconjuntos Vi que estén desunidos? La optimización de este
problema es NP-hard. Para resolver este problema, usaremos otra vez H = HA + HB, siendo:

HA = A * ∑(i,j : Vi ∩ Vj ≠ ∅)(xi * xj)

que controla que los subconjuntos estén desunidos, y

HB = −B * ∑(i) * xi

que cuenta el número de subconjuntos obtenidos. Haciendo que A > B nos aseguramos de que nunca se va a incumplir la condición que impone HA.

Sin embargo, podemos plantear este problema de otra forma. Si consideramos un grafo G = (V,E) donde cada conjunto Vi contiene un vértice i ∈ V. Una arista E existe
en ij cuando Vi ∩ Vj no está vacío. Se puede ver más fácilmente si sustituimos el HA anterior con: 

HA = A * ∑(i j ∈ E) xi * xj

Esta versión del problema se puede llamar "maximal independent set" (MIS).

4.3. Vertex Cover

Dado un grafo indirecto G = (V,E), ¿cuál es el menor número de vértices "coloreados" de tal forma que todos los vértices estén unidos a un vértice coloreado por una
arista? Pongamos xv como un valor binario de cada vértice, siendo 1 coloreado y 0 sin colorear. Nuestro hamiltoniano será otra vez H = HA + HB; siendo

HA = A * ∑(u v ∈ E)(1 − xu)(1 − xv)

que codifica la restricción de que cada arista está compuesta por al menos 1 vértice coloreado, y

HB = B * ∑(v)(xv)

que deberemos minimizar para obtener la solución a este problema. Si hacemos que A > B para asegurarnos de que la restricción de HA se cumple. El número de spins
necesarios es el número de vértices en el grafo.

4.4. Satisfiability

Todos los problemas de satisfacibilidad pueden ser tratados como un problema 3SAT. En este caso, veremos si

Ψ = C1 ∧ C2 ⋯ ∧ Cm

puede ser "verdadero". Por ejemplo, podemos ver si todos los Ci (1 ≤ i ≤ m) son verdadero, donde cada forma de Ci es:

Ci = yi1 ∨ yi2 ∨ yi3

Aquí, yi1, yi2 e yi3 son seleccionados de otro conjunto de valores booleanos x1,...,xN,x1',...,xN'.

Se puede reducir este problema a un MIS. Si tomamos como ejemplo el problema que planteamos en el punto 2 de Set Packing, tenemos un grafo con 3m nodos. Por cada
cláusula Ci, añadimos 3 nodos al grafo y lo conectamos con otros 3. Después de esto, deberíamos tener un y1 e y2 tal que y1 = y2', y añadimos otra arista entre esos
dos nodos. Resolviendo el problema como MIS y preguntándonos si la solución tiene exactamente m nodos, podemos resolver el problema por 3SAT.

Esto se puede interpretar de la siguiente manera: Si existe una solución 3SAT, significa que solo se necesita que una de las cláusulas sea verdadero. Si hay más
cláusulas verdaderas también es aceptable, pero debemos tener al menos una verdadera. Sin embargo, no podemos elegir que x1 y x1' sean ambos verdadero, para ello 
debemos conectar todos estos puntos con una arista. Ahora que el grafo está compuesto por m triángulos conectados, la única manera de colorear m vértices es que cada
vértice esté en un triángulo diferente haciendo que haya al menos un elemento en cada cláusula Ci que sea verdadero.

También se puede tomar este problema como un problema de optimización al preguntarnos cuál es el menor número de restricciones que debamos ignorar para resolver el
problema.

4.5. Minimal Maximal Matching

Los problemas de Minimax Matching de un grafo se definen de la siguiente manera: Si G = (V,E) como un grafo y C ⊆ E es un "coloreado" propuesto con las siguientes
restricciones: Por cada arista en C, se colorean los vértices que conectan (D = ∪e∈C ∂e). Necesitamos que ningún par de aristas compartan un mismo vértice
(e1, e2 ∈ C, ∂e1 ∩ ∂e2 = ∅) y que si u y v pertenecen a D, no pertenezcan a E. Esto tiene una parte de minimización ya que no se pueden añadir más aristas a C sin
violar la primera restricción; y de máximización ya que debemos incluir todas las aristas entre vértices sin colorear.

Podemos usar los spins en el grafo para modelar si una arista está coloreada o no (usando, por ejemplo, la variable xe). El número de spins es |E| = O(ΔN), o sea, el
tamaño del conjunto de aristas. Para codificar el problema, usamos una serie de 3 hamiltonianos:

H = HA + HB + HC

El primer hamiltoniano, HA, impondrá la condición de que un vértice no puede tener dos aristas coloreadas:

HA = A * ∑(v) (∑({e1, e2} ⊂ ∂v) (xe1 * xe2))

Siendo ∂v el subconjunto de E que conectan a v, y A > 0. El estado base sería HA = 0, ya que si fuese HA > 0 significaría que hay un vértice con dos o más aristas
coloreadas.

Definimos HB para que las soluciones que buscamos hagan que HB = 0. Usaremos HB para ver si hay alguna arista que no haya sido coloreada con:

HB = B * ∑(e=(uv))((1−yu) * (1−yv))





